import re
import emoji
import pymorphy3
from functools import lru_cache

# Инициализация морфологического анализатора
morph = pymorphy3.MorphAnalyzer()

# === РАСШИРЕННЫЙ СПИСОК СТОП-СЛОВ (Начальные формы!) ===
STOP_WORDS = {
    # Глаголы-связки и местоимения (начальные формы)
    'быть', 'есть', 'буду', 'будет', 'был', 'была', 'были', 'стать',
    'я', 'мы', 'ты', 'вы', 'он', 'она', 'оно', 'они', 
    'себя', 'свой', 'своя', 'своё', 'свои', 'мой', 'твой', 'наш', 'ваш', 'их', 'ее', 'его',
    
    # Указательные и относительные
    'тот', 'та', 'то', 'те', 'этот', 'эта', 'это', 'эти', 
    'который', 'которая', 'которое', 'которые', 'чей', 'чья', 'чье',
    'такой', 'такая', 'такое', 'такие', 'весь', 'вся', 'всё', 'все', 'всех',
    
    # Предлоги и союзы
    'и', 'в', 'во', 'не', 'на', 'с', 'со', 'что', 'а', 'по', 'к', 'но', 
    'как', 'из', 'у', 'за', 'от', 'для', 'же', 'бы', 'или', 'если', 
    'так', 'где', 'нет', 'да', 'ну', 'уже', 'ни', 'до', 'при', 'про', 
    'без', 'над', 'под', 'об', 'обо', 'ли', 'ведь', 'вот', 'там', 'тут', 
    'здесь', 'теперь', 'тогда', 'потом', 'потому', 'почему', 'чем', 'тем', 
    'когда', 'можно', 'нельзя', 'надо', 'нужно',
    
    # Мусорные наречия и вводные слова
    'очень', 'даже', 'просто', 'лишь', 'тоже', 'также', 'более', 'менее', 
    'вообще', 'совсем', 'почти', 'прям', 'вроде', 'типа', 'чисто', 
    'раз', 'два', 'три', 'много', 'мало', 'через'
}

@lru_cache(maxsize=50000)
def get_normal_form(word):
    """Кешируемая лемматизация"""
    try:
        return morph.parse(word)[0].normal_form
    except:
        return word

def preprocess_user_data(text):
    """
    Очистка текста:
    1. Смайлики в текст
    2. Лемматизация (приведение к начальной форме)
    3. Удаление стоп-слов (фильтрация мусора)
    """
    if not isinstance(text, str):
        return str(text)

    # 1. Регистр
    text = text.lower()
    
    # 2. Смайлики -> текст
    text = emoji.demojize(text, delimiters=(" ", " "))
    
    # 3. Чистка от мусора (оставляем буквы, цифры и двоеточие)
    text = re.sub(r'[^\w\s:]', ' ', text)
    
    # 4. Лемматизация и фильтрация
    words = text.split()
    clean_words = []
    
    for word in words:
        if len(word) > 1: # Игнорируем буквы-одиночки
            # Если это смайлик (например :fire:), оставляем как есть
            if word.startswith(':') and word.endswith(':'):
                clean_words.append(word)
            else:
                # Получаем начальную форму (был -> быть)
                lemma = get_normal_form(word)
                
                # Проверяем, нет ли начальной формы в черном списке
                if lemma not in STOP_WORDS:
                    clean_words.append(lemma)

    return " ".join(clean_words)
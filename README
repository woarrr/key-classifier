# Сервис анализа тональности отзывов

Данный репозиторий содержит full-stack веб-приложение, разработанное для автоматического анализа тональности пользовательских отзывов. Система принимает на вход наборы данных в форматах CSV или XLSX, обрабатывает текст с использованием методов обработки естественного языка (NLP) и классифицирует отзывы на положительные, негативные или нейтральные с использованием модели логистической регрессии.

## Архитектура системы

Решение построено на базе архитектуры Клиент-Сервер и контейнеризировано с использованием Docker.

Обзор компонентов:

1. Frontend (Клиентская часть):
   Разработан на React.js.
   Служит пользовательским интерфейсом для загрузки файлов, визуализации данных (графики, метрики) и ручной валидации.
   Хостинг осуществляется через Nginx в производственной среде.
   Взаимодействует с бэкендом посредством REST API.

2. Backend (Серверная часть):
   Разработан на Python с использованием фреймворка FastAPI.
   Отвечает за парсинг файлов (CSV/Excel), очистку данных и сериализацию.
   Предоставляет эндпоинты для анализа (/analyze) и валидации метрик (/validate).

3. ML Core (Ядро машинного обучения):
   Препроцессинг: Реализует нормализацию текста, лемматизацию (Pymorphy3), фильтрацию стоп-слов и преобразование эмодзи в текст.
   Модель: Векторизатор TF-IDF в связке с Логистической Регрессией (scikit-learn), загружаемая из сериализованного pickle-файла.

Поток данных:
Загрузка файла пользователем -> Nginx/React -> FastAPI -> Пайплайн препроцессинга -> Предсказание модели -> JSON ответ -> Визуализация на клиенте

## Технологический стек

Frontend: React, Recharts (визуализация), Lucide-react (иконки).
Backend: Python 3.10, FastAPI, Pandas, Scikit-learn, Pymorphy3.
Инфраструктура: Docker, Docker Compose.

## Логика классификации

Модель работает со следующей маркировкой классов согласно условиям задачи:
0: Нейтральный
1: Позитивный
2: Негативный

## Архитектура проекта

WAZI/
├── backend/ # Серверная часть (Python)
│ ├── main.py # Основной серверный скрипт
│ ├── preprocessing.py # Скрипт предварительной обработки данных
│ ├── final_logreg_tfidf_model.pkl # Обученная модель
│ ├── requirements.txt # Зависимости Python
│ ├── Dockerfile # Dockerfile для backend
│ └── top_emojis.json # Дополнительные данные
├── frontend/ # Клиентская часть (React + Vite)
│ ├── src/
│ │ ├── main.jsx
│ │ ├── App.jsx
│ │ └── assets/ # Стили и изображения
│ ├── public/ # Публичные файлы
│ ├── package.json
│ └── Dockerfile # Dockerfile для frontend
├── docker-compose.yaml # Сборка и запуск всех сервисов через Docker Compose
├── notebook_final.ipynb # Jupyter Notebook с экспериментами и обучением модели
└── README.md

## Установка и запуск

### Требования
Установленные Docker и Docker Compose.

### Запуск через Docker (Рекомендуется)

1. Клонирование репозитория:
   git clone https://github.com/woarrr/key-classifier.git
   cd key-classifier

2. Сборка и запуск контейнеров:
   docker-compose up --build

3. Доступ к приложению:
   Веб-интерфейс: http://localhost:3000
   API Документация: http://localhost:8000/docs

### Локальная разработка (Вручную)

Если Docker недоступен, компоненты можно запустить по отдельности.

Backend:
cd backend
pip install -r requirements.txt
python main.py
Сервер запустится на http://localhost:8000

Frontend:
cd frontend
npm install
npm run build
Запуск сервера разработки:
npm run dev

## Функциональность

Парсинг файлов: Обработка CSV и Excel файлов с автоматическим определением разделителей и кодировки.
Анализ данных:
   - Статистика распределения тональности.
   - Анализ источников отзывов.
   - Частотный анализ (топ значимых слов для каждой тональности).
Модуль валидации: Позволяет сравнивать предсказания модели с эталонным датасетом (Golden Dataset) с расчетом метрик Macro-F1, Precision, Recall и Accuracy.
Экспорт: Возможность скачивания размеченных данных в формате CSV.

## Структура проекта



ссылка на репозиторий: "https://github.com/woarrr/key-classifier">
